## Lab 1. Leveraging an OpenAI model to create extract data and create embeddings


### Task 1. Install all the required libraries using requirements.txt file


1. In Azure Portal, click on **Resource groups** from the Navigate panel.

   ![](https://raw.githubusercontent.com/CloudLabsAI-Azure/Migrating-DB-from-Single-Server-To-Flexible-Postgres/main/Images/E2T1S8.png)

1. From the Resource groups page, click on **ODL-AzureAI-MS-<inject key="PostGre SQL Password" enableCopy="false"/>**.

   ![](Images/e1t1s2.png)

1. From the **Overview (1)** tab select the Azure Machine Learning workspace **asamlworkspace<inject key="DeploymentID" enableCopy="false"/> (2)**.

   ![](Images/e1t1s3.png)
   
1. On Azure Machine Learning workspace click on **Launch studio**.

   ![](Images/e1t1s4.png)
   
1. On **Machine Learning Studio** page, click on **Notebooks (1)**, then click on **Add files (2)** and select **Upload folder (3)**.

    ![](Images/e1t1s5.png)
    
    > **Note :** If you see any pop-up naming **What's new in Notebooks** click on **Close**.

      ![](Images/close.png)
      
1. Click on **+** to upload the folder into the workspace.

   ![](Images/e1t1s6.png)
    
1. Navigate to the path **C:\LabFiles (1)** and select **artifacts (2)** folder.

   ![](Images/e1t1s7.png)
 
1. On the pop up tab click on **Upload** to upload the files to workspace.

    ![](Images/upload.png)
    
3. Check the box next to **I trust contents of this file (1)** and click on **Upload (2)**.

    ![](Images/e1t1s8.png)
    
   > **Note :** Wait for 5-10 minutes until the files get uploaded.


### Task 2 : Update the configuration file with newly generated credentials


### Task 3 : Experiment with notebooks to explore data and model

### Task 4 : Review all the modules
